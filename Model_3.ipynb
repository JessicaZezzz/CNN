{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNArxgX9ICtY/Ieroe5saOc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JessicaZezzz/CNN/blob/main/Model_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1s3CSe1MrSqs"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import skimage.io\n",
        "import os \n",
        "import tqdm\n",
        "import glob\n",
        "import tensorflow\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "from skimage.color import grey2rgb\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPool2D, Conv2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras import optimizers"
      ],
      "metadata": {
        "id": "5FGkfs1GrYKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import Callback,ModelCheckpoint\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import keras.backend as K\n",
        "\n",
        "from typeguard import typechecked\n",
        "from typing import Optional"
      ],
      "metadata": {
        "id": "SlRbEO824awq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "metadata": {
        "id": "0xnyLaq54lRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   validation_split = 0.2,\n",
        "                                  \n",
        "        rotation_range=5,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        #zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                  validation_split = 0.2)\n",
        "\n",
        "test_datagen  = ImageDataGenerator(rescale = 1./255)"
      ],
      "metadata": {
        "id": "xEycpDX-4lzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset  = train_datagen.flow_from_directory(directory = '/content/drive/MyDrive/Dataset/train',\n",
        "                                                   target_size = (128,128),\n",
        "                                                   class_mode = 'categorical',\n",
        "                                                   subset = 'training',\n",
        "                                                   batch_size = 32)"
      ],
      "metadata": {
        "id": "4WXXKeRH4tn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dataset = valid_datagen.flow_from_directory(directory = '/content/drive/MyDrive/Dataset/train',\n",
        "                                                  target_size = (128,128),\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  subset = 'validation',\n",
        "                                                  batch_size = 32)"
      ],
      "metadata": {
        "id": "zmNoMq6h4uJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = test_datagen.flow_from_directory(directory = '/content/drive/MyDrive/Dataset/test',\n",
        "                                                  target_size = (128,128),\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  batch_size = 32)"
      ],
      "metadata": {
        "id": "gba_Ucnn4yYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "modelFolder = 'model[0]/'\n",
        "\n",
        "checkpointLoss = ModelCheckpoint(\n",
        "    f\"{modelFolder}bestLoss.hdf5\",\n",
        "    monitor = 'loss',\n",
        "    verbose = 1,\n",
        "    save_best_only = True,\n",
        "    mode = 'auto'\n",
        ")\n",
        "\n",
        "checkpointValLoss = ModelCheckpoint(\n",
        "    f\"{modelFolder}bestValLoss.hdf5\",\n",
        "    monitor = 'val_loss',\n",
        "    verbose = 1,\n",
        "    save_best_only = True,\n",
        "    mode = 'auto'\n",
        ")\n",
        "\n",
        "earlyStopVal = EarlyStopping(monitor ='val_loss', mode='min', verbose =1, patience =10)\n",
        "earlyStop = EarlyStopping(monitor = 'loss', mode='min', verbose =1, patience =10)\n",
        "\n",
        "class myCallback(Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.91 and logs.get('loss')<0.001):\n",
        "      print('\\nAkurasi telah mencapai > 95% and loss < 0.001')\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "4trloXE2TZ7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, kernel_size=(3, 3),activation='relu',input_shape=(128,128,3)))\n",
        "model.add(MaxPooling2D(3,strides=1))\n",
        "model.add(Conv2D(32, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=1, padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=1, padding='same'))\n",
        "model.add(Conv2D(128, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=1, padding='same'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(550, activation='relu'))\n",
        "model.add(Dropout(0.1,seed = 2019))\n",
        "model.add(Dense(400, activation='relu'))\n",
        "model.add(Dropout(0.3,seed = 2019))\n",
        "model.add(Dense(300, activation='relu'))\n",
        "model.add(Dropout(0.4,seed = 2019))\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dropout(0.2,seed = 2019))\n",
        "model.add(Dense(4, activation='softmax'))"
      ],
      "metadata": {
        "id": "TaHv0QGJLeU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "kn5niTxDLlA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_score(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "metadata": {
        "id": "gJHgEKkW5HNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall'),  \n",
        "      tf.keras.metrics.AUC(name='auc'),\n",
        "        f1_score,\n",
        "]"
      ],
      "metadata": {
        "id": "QLuFgPZS5I8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exponential_decay(lr0, s):\n",
        "    def exponential_decay_fn(epoch):\n",
        "        return lr0 * 0.01 **(epoch / s)\n",
        "    return exponential_decay_fn\n",
        "\n",
        "exponential_decay_fn = exponential_decay(0.01, 5)\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)"
      ],
      "metadata": {
        "id": "vf-QS_1G5Kue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=METRICS)"
      ],
      "metadata": {
        "id": "64RBy-X95Mwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(train_dataset,\n",
        "                        validation_data=valid_dataset,\n",
        "                        epochs = 10,\n",
        "                        verbose = 1,\n",
        "                         callbacks=[callbacks,checkpointValLoss,earlyStopVal],)"
      ],
      "metadata": {
        "id": "PZ4XFQhQLoYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Train_Val_Plot(acc,val_acc,loss,val_loss,auc,val_auc,precision,val_precision,f1,val_f1):\n",
        "    \n",
        "    fig, (ax1, ax2,ax3,ax4,ax5) = plt.subplots(1,5, figsize= (20,5))\n",
        "    fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n",
        "\n",
        "    ax1.plot(range(1, len(acc) + 1), acc)\n",
        "    ax1.plot(range(1, len(val_acc) + 1), val_acc)\n",
        "    ax1.set_title('History of Accuracy')\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.legend(['training', 'validation'])\n",
        "    \n",
        "    ax2.plot(range(1, len(loss) + 1), loss)\n",
        "    ax2.plot(range(1, len(val_loss) + 1), val_loss)\n",
        "    ax2.set_title('History of Loss')\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.legend(['training', 'validation'])\n",
        "    \n",
        "    ax3.plot(range(1, len(auc) + 1), auc)\n",
        "    ax3.plot(range(1, len(val_auc) + 1), val_auc)\n",
        "    ax3.set_title('History of AUC')\n",
        "    ax3.set_xlabel('Epochs')\n",
        "    ax3.set_ylabel('AUC')\n",
        "    ax3.legend(['training', 'validation'])\n",
        "       \n",
        "    ax4.plot(range(1, len(precision) + 1), precision)\n",
        "    ax4.plot(range(1, len(val_precision) + 1), val_precision)\n",
        "    ax4.set_title('History of Precision')\n",
        "    ax4.set_xlabel('Epochs')\n",
        "    ax4.set_ylabel('Precision')\n",
        "    ax4.legend(['training', 'validation'])\n",
        "    \n",
        "    ax5.plot(range(1, len(f1) + 1), f1)\n",
        "    ax5.plot(range(1, len(val_f1) + 1), val_f1)\n",
        "    ax5.set_title('History of F1-score')\n",
        "    ax5.set_xlabel('Epochs')\n",
        "    ax5.set_ylabel('F1 score')\n",
        "    ax5.legend(['training', 'validation'])\n",
        "\n",
        "\n",
        "    plt.show()\n",
        "  \n",
        "Train_Val_Plot(history.history['accuracy'],history.history['val_accuracy'],\n",
        "               history.history['loss'],history.history['val_loss'],\n",
        "               history.history['auc'],history.history['val_auc'],\n",
        "               history.history['precision'],history.history['val_precision'],\n",
        "               history.history['f1_score'],history.history['val_f1_score']\n",
        "              )"
      ],
      "metadata": {
        "id": "ddrtOofG5Qpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate_generator(test_dataset)"
      ],
      "metadata": {
        "id": "Ki72SQtE5dkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy = \", scores[1])\n",
        "print(\"Precision = \", scores[2])\n",
        "print(\"Recall = \", scores[3])\n",
        "print(\"AUC = \", scores[4])\n",
        "print(\"F1_score = \", scores[5])"
      ],
      "metadata": {
        "id": "4UsHEPKx5fi8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}